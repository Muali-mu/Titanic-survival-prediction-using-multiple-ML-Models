üß† Titanic Survival Prediction - Machine Learning Models This project focuses on predicting passenger survival using the famous Titanic dataset from Kaggle. The objective is to apply multiple machine learning classification algorithms, analyze their performance, and compare their effectiveness.

üîç Dataset The Titanic dataset contains information about the passengers, such as age, sex, ticket class, fare, number of siblings/spouses aboard, and whether they survived or not. It is a binary classification problem where the target variable is Survived (1 = Yes, 0 = No).

‚úÖ Models Applied SVM (Support Vector Machine): A model that finds the optimal hyperplane to separate classes in high-dimensional space.

KNN (K-Nearest Neighbors): A distance-based classifier that predicts the class based on the majority vote from k-nearest neighbors.

Naive Bayes: A probabilistic classifier based on Bayes‚Äô Theorem assuming independence among predictors.

Decision Tree: A flowchart-like tree structure where each node represents a feature split leading to a decision.

Gradient Boosting: An ensemble technique that builds models sequentially, each correcting the errors of the previous one.

AdaBoost (Adaptive Boosting): An ensemble method that adjusts the weights of misclassified examples to improve performance.

LightGBM (Light Gradient Boosting Machine): A fast and efficient gradient boosting framework designed for better accuracy and speed.

üìä Evaluation Each model's performance was evaluated using metrics like accuracy, precision, recall, and F1-score, along with confusion matrices for detailed performance analysis.

üéØ Goal The aim is to identify which machine learning algorithm performs best on the Titanic dataset and gain insight into how different models handle real-world data.
